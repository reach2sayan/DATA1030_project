{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing basic tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_pp.csv')\n",
    "df_fit = df.drop(['date_day','id','album_id','date_month','decade'],axis=1) #as mentioned in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = df_fit.drop(['billboard'],axis=1)\n",
    "y = df_fit['billboard']\n",
    "\n",
    "\n",
    "\n",
    "splitter = TimeSeriesSplit(n_splits=2)\n",
    "for i_other,i_test in splitter.split(X, y):\n",
    "    X_other, y_other = X.iloc[i_other], y.iloc[i_other]\n",
    "    X_test, y_test = X.iloc[i_test], y.iloc[i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "columns = []\n",
    "for i in range(2):\n",
    "    columns.append('principal component '+str(i))\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = columns)\n",
    "\n",
    "principalDf.head()\n",
    "finalDf = pd.concat([principalDf, df_fit[['billboard']]], axis = 1)\n",
    "finalDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the first two principal axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0.0,1.0]\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = (finalDf['billboard'] == target)\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 0']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "plt.savefig('../figures/PCA1_2.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/grid0.xgboost', 'rb')\n",
    "grid_xgboost = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgboost.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Premutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_runs = 10\n",
    "scores = np.zeros([len(X_test.columns),nr_runs])\n",
    "\n",
    "test_score = grid_xgboost.score(X_test,y_test)\n",
    "print('test score = ',test_score)\n",
    "print('test baseline = ',np.sum(y_test == 1)/len(y_test))\n",
    "# loop through the features\n",
    "for i in range(len(X_test.columns)):\n",
    "    print('shuffling '+str(X_test.columns[i]))\n",
    "    acc_scores = []\n",
    "    for j in range(nr_runs):\n",
    "        X_test_shuffled = X_test.copy()\n",
    "        X_test_shuffled[X_test.columns[i]] = np.random.permutation(X_test[X_test.columns[i]].values)\n",
    "        acc_scores.append(grid_xgboost.score(X_test_shuffled,y_test))\n",
    "    print('   shuffled test score:',np.around(np.mean(acc_scores),8),'+/-',np.around(np.std(acc_scores),8))\n",
    "    scores[i] = acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the difference in score for each feature\n",
    "\n",
    "sorted_indcs = np.argsort(np.mean(scores,axis=1))[::-1]\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(scores[sorted_indcs].T,labels=(X_test.columns)[sorted_indcs],vert=False)\n",
    "plt.axvline(test_score,label='test score')\n",
    "plt.title(\"Permutation Importances (test set)\")\n",
    "plt.xlabel('score with perturbed feature')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_perm_imp_xgboost.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also comparing with SelectFromModel and using xgboost's plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = grid_xgboost.best_estimator_\n",
    "xgb = xgb['xgbclassifier']\n",
    "\n",
    "from xgboost import plot_importance\n",
    "plot_importance(xgb)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_imp_sfm_xgboost.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../results/randomForest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 5}\n",
      "best CV score: 0.8950995295136275\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3aa61c0c8f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best CV score:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test score:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in ['grid0.RandomForest','grid1.RandomForest','grid2.RandomForest','grid3.RandomForest']:\n",
    "    file = open('../results/randomForest/'+i, 'rb')\n",
    "    grid = pickle.load(file)\n",
    "    file.close()\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing the best score with minimum splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/randomForest/grid1.RandomForest', 'rb')\n",
    "grid_randomforest = pickle.load(file)\n",
    "file.close()\n",
    "rndfor = grid_randomforest.best_estimator_['randomforestclassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndfor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_runs = 10\n",
    "scores = np.zeros([len(X_test.columns),nr_runs])\n",
    "\n",
    "test_score = grid_randomforest.score(X_test,y_test)\n",
    "print('test score = ',test_score)\n",
    "print('test baseline = ',np.sum(y_test == 1)/len(y_test))\n",
    "# loop through the features\n",
    "for i in range(len(X_test.columns)):\n",
    "    print('shuffling '+str(X_test.columns[i]))\n",
    "    acc_scores = []\n",
    "    for j in range(nr_runs):\n",
    "        X_test_shuffled = X_test.copy()\n",
    "        X_test_shuffled[X_test.columns[i]] = np.random.permutation(X_test[X_test.columns[i]].values)\n",
    "        acc_scores.append(grid_randomforest.score(X_test_shuffled,y_test))\n",
    "    print('   shuffled test score:',np.around(np.mean(acc_scores),3),'+/-',np.around(np.std(acc_scores),3))\n",
    "    scores[i] = acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indcs = np.argsort(np.mean(scores,axis=1))[::-1]\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(scores[sorted_indcs].T,labels=(X_test.columns)[sorted_indcs],vert=False)\n",
    "plt.axvline(test_score,label='test score')\n",
    "plt.title(\"Permutation Importances (test set)\")\n",
    "plt.xlabel('score with perturbed feature')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_perm_imp_randfor.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn random forests own feature_importance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = X_test.columns\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rndfor.feature_importances_), names), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rndfor.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rndfor.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_other.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_other.shape[1]), X_other.columns[indices],rotation=90)\n",
    "plt.xlim([-1, X_other.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_imp_randfor.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print a forest from the list of fit forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "estimator = rndfor.estimators_[0]\n",
    "\n",
    "export_graphviz(estimator, out_file='../figures/tree_randfor.dot', \n",
    "                feature_names = X_other.columns,\n",
    "                class_names = ['0','1'],\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "call(['dot', '-Tpng', '../figures/tree_randfor.dot', '-o', '../figures/tree_randfor.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "\n",
    "Image(filename = '../figures/tree_randfor.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndfor.estimators_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['grid0.adaboost','grid1.adaboost','grid2.adaboost','grid3.adaboost']:\n",
    "    file = open('../results/adaboost/'+i, 'rb')\n",
    "    grid = pickle.load(file)\n",
    "    file.close()\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing the best score parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../results/adaboost/grid1.adaboost', 'rb')\n",
    "grid_adaboost = pickle.load(file)\n",
    "file.close()\n",
    "adbc = grid_adaboost.best_estimator_['adaboostclassifier']\n",
    "adbc.estimator_errors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the tree with the least error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "estimator = adbc.estimators_[0]\n",
    "export_graphviz(estimator, out_file='../figures/tree_adaboost.dot', \n",
    "                feature_names = X_other.columns,\n",
    "                class_names = ['0','1'],\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "call(['dot', '-Tpng', '../figures/tree_adaboost.dot', '-o', '../figures/tree_adaboost.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "\n",
    "Image(filename = '../figures/tree_adaboost.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn adaboosts own feature_importance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = adbc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in adbc.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_other.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_other.shape[1]), X_other.columns[indices],rotation=90)\n",
    "plt.xlim([-1, X_other.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/feature_imp_adaboost.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_runs = 10\n",
    "scores = np.zeros([len(X_test.columns),nr_runs])\n",
    "\n",
    "test_score = grid_adaboost.score(X_test,y_test)\n",
    "print('test score = ',test_score)\n",
    "print('test baseline = ',np.sum(y_test == 1)/len(y_test))\n",
    "# loop through the features\n",
    "for i in range(len(X_test.columns)):\n",
    "    print('shuffling '+str(X_test.columns[i]))\n",
    "    acc_scores = []\n",
    "    for j in range(nr_runs):\n",
    "        X_test_shuffled = X_test.copy()\n",
    "        X_test_shuffled[X_test.columns[i]] = np.random.permutation(X_test[X_test.columns[i]].values)\n",
    "        acc_scores.append(grid_randomforest.score(X_test_shuffled,y_test))\n",
    "    print('   shuffled test score:',np.around(np.mean(acc_scores),3),'+/-',np.around(np.std(acc_scores),3))\n",
    "    scores[i] = acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indcs = np.argsort(np.mean(scores,axis=1))[::-1]\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(scores[sorted_indcs].T,labels=(X_test.columns)[sorted_indcs],vert=False)\n",
    "plt.axvline(test_score,label='test score')\n",
    "plt.title(\"Permutation Importances (test set)\")\n",
    "plt.xlabel('score with perturbed feature')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plt.savefig('../figures/feature_perm_imp_adaboost.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = grid_randomforest.predict(X_test) # I usually replaced them with the appropriate grid names \n",
    "                                           # grid_xgboost or grid_adaboost\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = np.array(classes)\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_true,y_pred,classes=['not billboard','billboard'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/randomforest_cm_normed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
